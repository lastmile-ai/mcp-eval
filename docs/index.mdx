---
title: "MCP‑Eval"
description: "Evaluate MCP servers and tool‑using agents with OTEL‑backed metrics, rich assertions, and multiple test styles."
icon: "house"
sidebarTitle: "Home"
mode: "custom"
---

<div style={{textAlign:'center', marginTop: 32, marginBottom: 32}}>
  <h1>MCP‑Eval</h1>
  <p>Flight simulator for tool‑using LLMs — connect an agent, exercise real tools, assert behavior and quality.</p>
</div>

### Start here

- [Overview](./overview.mdx)
- [Quickstart](./quickstart.mdx)
- [Detailed Guide](./detailed_guide.mdx)

### Core concepts

- [Concepts](./concepts.mdx)
- [Metrics & Tracing](./metrics-tracing.mdx)

### Evaluate

- [Agent Evaluation](./agent-evaluation.mdx)
- [MCP Server Evaluation](./server-evaluation.mdx)

### Author tests

- [Assertions](./assertions.mdx)
- [Pytest](./pytest.mdx)
- [Datasets](./datasets.mdx)
- [Agents](./agents.mdx)

### Operate

- [Configuration](./configuration.mdx)
- [CLI Reference](./cli-reference.mdx)
- [Test Generation](./test-generation.mdx)
- [CI/CD](./ci-cd.mdx)
- [Troubleshooting](./troubleshooting.mdx)
- [FAQ](./faq.mdx)
- [Changelog](./changelog.mdx)

<!-- TODO: Add a hero illustration and quick demo gif of `mcp-eval run`. -->

